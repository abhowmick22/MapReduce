Functionality of the distributed processing framework
-----------------------------------------------------

1. JobTracker does the following tasks
	- Schedule jobs on the slave nodes
	- Run a monitor daemon to check the jobs on the slave nodes
	- re-execute jobs on the slave jobs in the event of failures
	
2. TaskTracker needs to run an RMI providing following services
	-
	
3. Task
	- assume we only get the dfs file path, and invoke a method at the master to 
	  get the local file system path
	- also, we run map/reduce tasks as services bound to a registry (this is the pool)
	
4. Implement a way for jobTracker to receive jobs from clientAPI

5. Assume jobTracker listens for messages from slaves on port 10000
   and from clients on port 20000
   
6. Tasktracker need not be highly efficient in accepting job requests, since it can only
   take decisions on whether to accept jobs based on previous outcomes. So it will be
   processing requests sequentially
   
7. We would like to allow different jobtrackers to be able to use different scheduleres,
   hence scheduler is not a static object
   
8. Assumption is that maps finish before reduce tasks