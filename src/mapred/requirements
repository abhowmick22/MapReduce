Functionality of the distributed processing framework
-----------------------------------------------------

1. JobTracker does the following tasks
	- Schedule jobs on the slave nodes
	- Run a monitor daemon to check the jobs on the slave nodes
	- re-execute jobs on the slave jobs in the event of failures
	
2. TaskTracker needs to run an RMI providing following services
	-
	
3. Task
	- assume we only get the dfs file path, and invoke a method at the master to 
	  get the local file system path
	- also, we run map/reduce tasks as services bound to a registry (this is the pool)
	
4. Implement a way for jobTracker to receive jobs from clientAPI

5. Assume jobTracker listens for messages from slaves on port 10000 and sends messages to slaves on 10001
   Also,from clientAPI on port 20000, and also sends messages to clientAPI on port 20001
   
6. Tasktracker need not be highly efficient in accepting job requests, since it can only
   take decisions on whether to accept jobs based on previous outcomes. So it will be
   processing requests sequentially
   
7. We would like to allow different jobtrackers to be able to use different scheduleres,
   hence scheduler is not a static object
   
8. Assumption is that maps finish before reduce tasks

9. Files are always refered to by a name, which is unique across the system. The mapper/
   reeducer which operates on these files fetch the physical location on the LFS from a
   service on the namenode, before starting to work on them. 