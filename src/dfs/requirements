Distributed File System:
1. started from the namenode
2. contains the following:
	- A trie consisting of the file system structure
	- At each node in the trie is a directory; it also stores an array list of
	
Requirements from Admin for DFS:
1. Add datanode names and total number of datanodes in config file
2. 

Requirements from the client for DFS:
1. Client provides file upload path on DFS
2. Client provides DFS input and output paths for accessing files
3. A client can add files only to its own username. The username for a client is the machine name
that he is logged in from. ClientAPI checks whether the path of a file on DFS starts with "/dfs/username/"

Messages to NameNode:
1. "NewFile" - add new file to DFS; also send back to client api the names of the datanodes where to replicate

TODO:
1. Replicate only on nodes with less data on their disk, or with more processing power currently? Doing
the former right now.


Adding and deleting files from DFS:
1. Client "adds" file to DFS by giving its local path to Client API, and the DFS path where the file should be placed.
The client api sends the DFS address to DFS service by calling the "addFileToDFS" method. 
2. The DFS, in response to this, creates the path to the file on the DFS, and for the file, assigns the number of 
blocks according to replication factor. It selects the datanodes according to min load, and sends the list to 
client api.
3. Client api then creates blocks and copies them to the datanodes. It distributes the blocks such that each
of the datanodes gets almost equal number but unique blocks.
4. Finally, the datanodes notify the DFS about which block(s) is given to each datanode. The DFS updates the final
mappping of nodename to block(s) in its dfsMetadata data structure.

On the datanode's local file system, the blocks of a file will be stored in LocalBaseDir/username directory